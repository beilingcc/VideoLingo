# ------------
# æœ¬æ¨¡å—ç”¨äºéŸ³é¢‘é¢„å¤„ç†ï¼ŒåŒ…æ‹¬éŸ³é‡å½’ä¸€åŒ–ã€è§†é¢‘è½¬éŸ³é¢‘ã€éŸ³é¢‘åˆ†å‰²ã€è½¬å½•ç»“æœå¤„ç†ç­‰
# ------------
import os, subprocess
import pandas as pd
from typing import Dict, List, Tuple
from pydub import AudioSegment
from core.utils import *
from core.utils.models import *
from pydub import AudioSegment
from pydub.silence import detect_silence
from pydub.utils import mediainfo
from rich import print as rprint

# ------------
# éŸ³é‡å½’ä¸€åŒ–
# ------------
def normalize_audio_volume(audio_path, output_path, target_db = -20.0, format = "wav"):
    audio = AudioSegment.from_file(audio_path)
    change_in_dBFS = target_db - audio.dBFS
    normalized_audio = audio.apply_gain(change_in_dBFS)
    normalized_audio.export(output_path, format=format)
    rprint(f"[green]âœ… éŸ³é¢‘éŸ³é‡å·²å½’ä¸€åŒ–: {audio.dBFS:.1f}dB â†’ {target_db:.1f}dB[/green]")
    return output_path

# ------------
# è§†é¢‘è½¬éŸ³é¢‘ï¼ˆffmpegï¼‰
# ------------
def convert_video_to_audio(video_file):
    os.makedirs(_AUDIO_DIR, exist_ok=True)
    if not os.path.exists(_RAW_AUDIO_FILE):
        rprint(f"[blue]ğŸ¬â¡ï¸ğŸµ æ­£åœ¨ç”¨FFmpegé«˜è´¨é‡æå–éŸ³é¢‘...[/blue]")
        subprocess.run([
            'ffmpeg', '-y', '-i', video_file, '-vn',
            '-c:a', 'libmp3lame', '-b:a', '32k',
            '-ar', '16000',
            '-ac', '1', 
            '-metadata', 'encoding=UTF-8', _RAW_AUDIO_FILE
        ], check=True, stderr=subprocess.PIPE)
        rprint(f"[green]ğŸ¬â¡ï¸ğŸµ <{video_file}> å·²è½¬ä¸º <{_RAW_AUDIO_FILE}>\n[/green]")

# ------------
# è·å–éŸ³é¢‘æ—¶é•¿
# ------------
def get_audio_duration(audio_file):
    """ç”¨ffmpegè·å–éŸ³é¢‘æ—¶é•¿"""
    cmd = ['ffmpeg', '-i', audio_file]
    process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    _, stderr = process.communicate()
    output = stderr.decode('utf-8', errors='ignore')
    try:
        duration_str = [line for line in output.split('\n') if 'Duration' in line][0]
        duration_parts = duration_str.split('Duration: ')[1].split(',')[0].split(':')
        duration = float(duration_parts[0])*3600 + float(duration_parts[1])*60 + float(duration_parts[2])
    except Exception as e:
        print(f"[red]âŒ è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}[/red]")
        duration = 0
    return duration

# ------------
# éŸ³é¢‘åˆ†å‰²ï¼Œè‡ªåŠ¨å¯»æ‰¾é™é»˜ç‚¹
# ------------
def split_audio(audio_file, target_len = 30*60, win = 60):
    # åœ¨ [target_len-win, target_len+win] åŒºé—´å†…ç”¨pydubæ£€æµ‹é™é»˜ï¼Œåˆ‡åˆ†éŸ³é¢‘
    rprint(f"[blue]ğŸ™ï¸ å¼€å§‹éŸ³é¢‘åˆ†å‰² {audio_file} {target_len} {win}[/blue]")
    audio = AudioSegment.from_file(audio_file)
    duration = float(mediainfo(audio_file)["duration"])
    if duration <= target_len + win:
        return [(0, duration)]
    segments, pos = [], 0.0
    safe_margin = 0.5  # é™é»˜ç‚¹å‰åå®‰å…¨è¾¹ç•Œï¼Œå•ä½ç§’
    while pos < duration:
        if duration - pos <= target_len:
            segments.append((pos, duration)); break
        threshold = pos + target_len
        ws, we = int((threshold - win) * 1000), int((threshold + win) * 1000)
        # è·å–å®Œæ•´çš„é™é»˜åŒºé—´
        silence_regions = detect_silence(audio[ws:we], min_silence_len=int(safe_margin*1000), silence_thresh=-30)
        silence_regions = [(s/1000 + (threshold - win), e/1000 + (threshold - win)) for s, e in silence_regions]
        # ç­›é€‰é•¿åº¦è¶³å¤Ÿä¸”ä½ç½®åˆé€‚çš„é™é»˜åŒºé—´
        valid_regions = [
            (start, end) for start, end in silence_regions 
            if (end - start) >= (safe_margin * 2) and threshold <= start + safe_margin <= threshold + win
        ]
        if valid_regions:
            start, end = valid_regions[0]
            split_at = start + safe_margin  # åœ¨é™é»˜åŒºé—´èµ·å§‹ç‚¹å0.5ç§’å¤„åˆ‡åˆ†
        else:
            rprint(f"[yellow]âš ï¸ {audio_file} {threshold}s æœªæ‰¾åˆ°åˆé€‚é™é»˜åŒºï¼Œç›´æ¥ç”¨é˜ˆå€¼åˆ‡åˆ†[/yellow]")
            split_at = threshold
        segments.append((pos, split_at)); pos = split_at
    rprint(f"[green]ğŸ™ï¸ éŸ³é¢‘åˆ†å‰²å®Œæˆï¼Œå…±{len(segments)}æ®µ[/green]")
    return segments

# ------------
# å¤„ç†è½¬å½•ç»“æœï¼Œæ•´ç†ä¸ºDataFrame
# ------------
def process_transcription(result):
    all_words = []
    for segment in result['segments']:
        # è·å–è¯´è¯äººid
        speaker_id = segment.get('speaker_id', None)
        for word in segment['words']:
            # æ£€æŸ¥å•è¯é•¿åº¦
            if len(word["word"]) > 30:
                rprint(f"[yellow]âš ï¸ æ£€æµ‹åˆ°è¶…é•¿å•è¯ï¼Œè·³è¿‡: {word['word']}[/yellow]")
                continue
            # æ³•è¯­ç‰¹æ®Šå¤„ç†
            word["word"] = word["word"].replace('Â»', '').replace('Â«', '')
            if 'start' not in word and 'end' not in word:
                if all_words:
                    # æ²¡æœ‰æ—¶é—´æˆ³ï¼Œç»§æ‰¿ä¸Šä¸€ä¸ªå•è¯çš„ç»“æŸæ—¶é—´
                    word_dict = {
                        'text': word["word"],
                        'start': all_words[-1]['end'],
                        'end': all_words[-1]['end'],
                        'speaker_id': speaker_id
                    }
                    all_words.append(word_dict)
                else:
                    # ç¬¬ä¸€ä¸ªè¯ï¼Œå‘åæ‰¾æœ‰æ—¶é—´æˆ³çš„è¯
                    next_word = next((w for w in segment['words'] if 'start' in w and 'end' in w), None)
                    if next_word:
                        word_dict = {
                            'text': word["word"],
                            'start': next_word["start"],
                            'end': next_word["end"],
                            'speaker_id': speaker_id
                        }
                        all_words.append(word_dict)
                    else:
                        raise Exception(f"æœªæ‰¾åˆ°ä¸‹ä¸€ä¸ªå¸¦æ—¶é—´æˆ³çš„è¯: {word}")
            else:
                # æ­£å¸¸æƒ…å†µ
                word_dict = {
                    'text': f'{word["word"]}',
                    'start': word.get('start', all_words[-1]['end'] if all_words else 0),
                    'end': word['end'],
                    'speaker_id': speaker_id
                }
                all_words.append(word_dict)
    return pd.DataFrame(all_words)

# ------------
# ä¿å­˜ç»“æœåˆ°Excel
# ------------
def save_results(df):
    os.makedirs('output/log', exist_ok=True)
    # åˆ é™¤ç©ºæ–‡æœ¬è¡Œ
    initial_rows = len(df)
    df = df[df['text'].str.len() > 0]
    removed_rows = initial_rows - len(df)
    if removed_rows > 0:
        rprint(f"[blue]â„¹ï¸ ç§»é™¤{removed_rows}è¡Œç©ºæ–‡æœ¬[/blue]")
    # æ£€æŸ¥è¶…é•¿å•è¯
    long_words = df[df['text'].str.len() > 30]
    if not long_words.empty:
        rprint(f"[yellow]âš ï¸ æ£€æµ‹åˆ°{len(long_words)}ä¸ªè¶…é•¿å•è¯ï¼Œå·²ç§»é™¤[/yellow]")
        df = df[df['text'].str.len() <= 30]
    df['text'] = df['text'].apply(lambda x: f'"{x}"')
    df.to_excel(_2_CLEANED_CHUNKS, index=False)
    rprint(f"[green]ğŸ“Š Excelå·²ä¿å­˜åˆ° {_2_CLEANED_CHUNKS}[/green]")

# ------------
# ä¿å­˜æ£€æµ‹åˆ°çš„è¯­è¨€
# ------------
def save_language(language):
    update_key("whisper.detected_language", language)