# ------------
# è¯¥æ¨¡å—ç”¨äºè°ƒç”¨302.aiçš„WhisperX APIè¿›è¡ŒéŸ³é¢‘è½¬å½•ï¼Œå¹¶å¯¹ç»“æœè¿›è¡Œç¼“å­˜
# ------------
import os
import io
import json
import time
import requests
import librosa
import soundfile as sf
from rich import print as rprint
from core.utils import *
from core.utils.models import *

# è¾“å‡ºæ—¥å¿—ç›®å½•
OUTPUT_LOG_DIR = "output/log"

# ------------
# ä½¿ç”¨302.ai WhisperX APIè¿›è¡ŒéŸ³é¢‘è½¬å½•
# æ”¯æŒå¯¹éŸ³é¢‘ç‰‡æ®µè¿›è¡Œåˆ‡ç‰‡ã€ç¼“å­˜ã€å…¨å±€æ—¶é—´æˆ³åç§»ç­‰
# ------------
def transcribe_audio_302(raw_audio_path, vocal_audio_path, start = None, end = None):
    """
    ä½¿ç”¨302.aiçš„WhisperX APIè¿›è¡ŒéŸ³é¢‘è½¬å½•ï¼Œå¹¶å¯¹ç»“æœè¿›è¡Œç¼“å­˜ã€‚
    å‚æ•°:
        raw_audio_path (str): åŸå§‹éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        vocal_audio_path (str): äººå£°éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        start (float): èµ·å§‹æ—¶é—´ï¼ˆç§’ï¼‰
        end (float): ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
    è¿”å›:
        dict: è½¬å½•ç»“æœï¼ˆåŒ…å«åˆ†æ®µå’Œè¯çº§æ—¶é—´æˆ³ï¼‰
    """
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    os.makedirs(OUTPUT_LOG_DIR, exist_ok=True)
    LOG_FILE = f"{OUTPUT_LOG_DIR}/whisperx302_{start}_{end}.json"
    # å¦‚æœå·²å­˜åœ¨ç¼“å­˜ï¼Œç›´æ¥è¯»å–
    if os.path.exists(LOG_FILE):
        with open(LOG_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    # è·å–è¯­è¨€è®¾ç½®
    WHISPER_LANGUAGE = load_key("whisper.language")
    update_key("whisper.language", WHISPER_LANGUAGE)
    url = "https://api.302.ai/302/whisperx"
    # è¯»å–éŸ³é¢‘å¹¶æŒ‰éœ€åˆ‡ç‰‡
    y, sr = librosa.load(vocal_audio_path, sr=16000)
    audio_duration = len(y) / sr
    if start is None or end is None:
        start = 0
        end = audio_duration
    start_sample = int(start * sr)
    end_sample = int(end * sr)
    y_slice = y[start_sample:end_sample]
    # å†™å…¥å†…å­˜ç¼“å†²åŒº
    audio_buffer = io.BytesIO()
    sf.write(audio_buffer, y_slice, sr, format='WAV', subtype='PCM_16')
    audio_buffer.seek(0)
    # æ„é€ APIè¯·æ±‚
    files = [('audio_input', ('audio_slice.wav', audio_buffer, 'application/octet-stream'))]
    payload = {"processing_type": "align", "language": WHISPER_LANGUAGE, "output": "raw"}
    start_time = time.time()
    rprint(f"[cyan]ğŸ¤ æ­£åœ¨è½¬å½•éŸ³é¢‘ï¼Œè¯­è¨€:  <{WHISPER_LANGUAGE}> ...[/cyan]")
    headers = {'Authorization': f'Bearer {load_key("whisper.whisperX_302_api_key")}' }
    response = requests.request("POST", url, headers=headers, data=payload, files=files)
    response_json = response.json()
    # å¯¹åˆ†æ®µå’Œè¯çº§æ—¶é—´æˆ³è¿›è¡Œå…¨å±€åç§»
    if start is not None:
        for segment in response_json['segments']:
            segment['start'] += start
            segment['end'] += start
            for word in segment.get('words', []):
                if 'start' in word:
                    word['start'] += start
                if 'end' in word:
                    word['end'] += start
    # ç¼“å­˜ç»“æœ
    with open(LOG_FILE, "w", encoding="utf-8") as f:
        json.dump(response_json, f, indent=4, ensure_ascii=False)
    elapsed_time = time.time() - start_time
    rprint(f"[green]âœ“ è½¬å½•å®Œæˆï¼Œç”¨æ—¶ {elapsed_time:.2f} ç§’[/green]")
    return response_json

if __name__ == "__main__":
    # ------------
    # æµ‹è¯•ä¸»ç¨‹åºï¼Œç›´æ¥è½¬å½•_RAW_AUDIO_FILE
    # ------------
    result = transcribe_audio_302(_RAW_AUDIO_FILE, _RAW_AUDIO_FILE)
    rprint(result)
