# -*- coding: utf-8 -*-
"""
æ™ºèƒ½é…éŸ³åˆ†å—ä¸è¯­é€Ÿåˆ†ææ¨¡å—

æœ¬æ¨¡å—æ‰¿æ¥ `_8_1_audio_task` ç”Ÿæˆçš„åˆæ­¥éŸ³é¢‘ä»»åŠ¡åˆ—è¡¨ï¼Œè¿›è¡Œæ·±åº¦çš„æ—¶åºå’Œè¯­é€Ÿåˆ†æï¼Œ
æ—¨åœ¨é€šè¿‡æ™ºèƒ½åˆå¹¶å­—å¹•è¡Œï¼Œåˆ›å»ºå‡ºæœ€é€‚åˆTTSï¼ˆæ–‡æœ¬è½¬è¯­éŸ³ï¼‰å¤„ç†çš„â€œé…éŸ³å—â€(dubbing chunks)ã€‚
å…¶æ ¸å¿ƒç›®æ ‡æ˜¯è§£å†³å•ä¸ªå­—å¹•è¡Œæ—¶é•¿è¿‡çŸ­ã€è¯­é€Ÿè¿‡å¿«çš„é—®é¢˜ï¼Œç¡®ä¿ç”Ÿæˆçš„é…éŸ³æµç•…è‡ªç„¶ã€‚

æ ¸å¿ƒåŠŸèƒ½:
1.  **æ—¶åºä¸è¯­é€Ÿåˆ†æ (`analyze_subtitle_timing_and_speed`)**:
    - **è®¡ç®—é—´éš™ (Gap Calculation)**: è®¡ç®—æ¯ä¸¤è¡Œå­—å¹•ä¹‹é—´çš„æ—¶é—´é—´éš”ï¼ˆ`gap`ï¼‰ï¼Œ
      ä»¥åŠæœ€åä¸€è¡Œå­—å¹•åˆ°è§†é¢‘ç»“å°¾çš„é—´éš™ã€‚è¿™æ˜¯åˆ¤æ–­æ˜¯å¦å¯ä»¥åˆå¹¶å­—å¹•çš„å…³é”®ä¾æ®ã€‚
    - **å®¹å¿æ—¶é•¿ (Tolerable Duration)**: åŸºäº`gap`å’Œé¢„è®¾çš„`TOLERANCE`å€¼ï¼Œè®¡ç®—å‡º
      æ¯è¡Œå­—å¹•çš„â€œå¯å®¹å¿æ—¶é•¿â€(`tol_dur`)ï¼Œå³ `duration + tolerance`ã€‚è¿™ä»£è¡¨äº†
      TTSç”ŸæˆéŸ³é¢‘æ—¶å¯ä»¥â€œå€Ÿç”¨â€çš„é¢å¤–æ—¶é—´ã€‚
    - **é¢„ä¼°æœ—è¯»æ—¶é•¿ (Estimated Duration)**: ä½¿ç”¨ `estimate_duration` å‡½æ•°ä¼°ç®—
      æ¯è¡Œæ–‡æœ¬çš„å®é™…æœ—è¯»æ—¶é—´ (`est_dur`)ã€‚
    - **è¯­é€ŸçŠ¶æ€æ ‡è®° (`if_too_fast`)**: åŸºäº `est_dur` å’Œ `tol_dur`ï¼Œä¸ºæ¯è¡Œ
      å­—å¹•æ‰“ä¸Šè¯­é€Ÿæ ‡è®°ï¼š
        - `2`: æå¿«ã€‚å³ä½¿è°ƒåˆ°æœ€å¤§è¯­é€Ÿä¹Ÿæ— æ³•åœ¨ `tol_dur` å†…å®Œæˆæœ—è¯»ã€‚
        - `1`: åå¿«ã€‚éœ€è¦åœ¨ `tol_dur` å†…å®Œæˆï¼Œéœ€è¦åŠ é€Ÿã€‚
        - `0`: æ­£å¸¸ã€‚è¯­é€Ÿåœ¨æ­£å¸¸èŒƒå›´å†…ã€‚
        - `-1`: åæ…¢ã€‚æœ—è¯»æ—¶é—´è¿œå°äº `duration`ã€‚

2.  **æ™ºèƒ½åˆ‡åˆ†ç‚¹å¤„ç† (`process_cutoffs` & `merge_rows`)**:
    - **åˆå§‹åŒ–åˆ‡åˆ†ç‚¹**: é»˜è®¤åœ¨`gap`å¤§äº`TOLERANCE`çš„åœ°æ–¹è®¾ç½®åˆ‡åˆ†ç‚¹ (`cut_off=1`)ï¼Œ
      å› ä¸ºå¤§çš„åœé¡¿é€šå¸¸æ˜¯å¤©ç„¶çš„åˆ†å‰²ç‚¹ã€‚
    - **åˆå¹¶é€»è¾‘**: éå†å­—å¹•è¡Œï¼Œå½“é‡åˆ°è¯­é€Ÿæ­£å¸¸æˆ–åæ…¢çš„è¡Œï¼Œå¦‚æœä¸‹ä¸€è¡Œè¯­é€Ÿä¹Ÿæ­£å¸¸æˆ–åæ…¢ï¼Œ
      åˆ™å½“å‰è¡Œå¯ç‹¬ç«‹ä¸ºä¸€ä¸ªç‰‡æ®µã€‚å¦‚æœä¸‹ä¸€è¡Œè¯­é€Ÿåå¿«ï¼Œåˆ™è§¦å‘ `merge_rows` åˆå¹¶é€»è¾‘ã€‚
      å½“é‡åˆ°è¯­é€Ÿåå¿«çš„è¡Œï¼Œä¹Ÿè§¦å‘ `merge_rows`ã€‚
    - **`merge_rows`**: è¿™æ˜¯ä¸€ä¸ªè¿­ä»£åˆå¹¶å‡½æ•°ã€‚å®ƒä¼šä»ä¸€ä¸ªèµ·å§‹è¡Œå¼€å§‹ï¼Œä¸æ–­å‘ååˆå¹¶
      åç»­è¡Œï¼ˆæœ€å¤šåˆå¹¶`MAX_MERGE_COUNT`è¡Œï¼‰ï¼Œå¹¶åœ¨æ¯ä¸€æ­¥éƒ½é‡æ–°è®¡ç®—åˆå¹¶åç‰‡æ®µçš„
      æ€»`est_dur`å’Œæ€»`tol_dur`ã€‚åˆå¹¶ä¼šæŒç»­åˆ°ä»¥ä¸‹ä»»ä¸€æ¡ä»¶æ»¡è¶³ï¼š
        - åˆå¹¶åçš„ç‰‡æ®µè¯­é€Ÿå˜ä¸ºæ­£å¸¸æˆ–åæ…¢ (`speed_flag <= 0`)ã€‚
        - è¾¾åˆ°é¢„è®¾çš„åˆå¹¶ä¸Šé™ã€‚
      ä¸€æ—¦æ‰¾åˆ°åˆé€‚çš„åˆå¹¶ç»ˆç‚¹ï¼Œå°±åœ¨è¯¥è¡Œæ‰“ä¸Š `cut_off=1` æ ‡è®°ã€‚

3.  **ç”Ÿæˆæœ€ç»ˆé…éŸ³å— (`gen_dub_chunks`)**:
    - **åŠ è½½ä¸åˆ†æ**: åŠ è½½ `_8_1_AUDIO_TASK.xlsx`ï¼Œå¹¶è°ƒç”¨ä¸Šè¿°åˆ†æå’Œå¤„ç†å‡½æ•°ã€‚
    - **æ–‡æœ¬åŒ¹é…ä¸é‡ç»„**: ç”±äºåˆ†æè¿‡ç¨‹ä¸­åˆå¹¶äº†è¡Œï¼Œéœ€è¦å°†åŸå§‹SRTæ–‡ä»¶ä¸­çš„å¤šè¡Œæ–‡æœ¬
      é‡æ–°ç»„åˆï¼Œä»¥åŒ¹é…åˆå¹¶åçš„DataFrameè¡Œã€‚å®ƒé€šè¿‡ `clean_text` æ¸…ç†å¹¶æ‹¼æ¥
      åŸå§‹SRTè¡Œï¼Œç›´åˆ°ä¸DataFrameä¸­åˆå¹¶åçš„`text`å­—æ®µå®Œå…¨åŒ¹é…ã€‚
    - **ä¿å­˜ç»“æœ**: å°†å¸¦æœ‰`cut_off`æ ‡è®°ã€åˆå¹¶åæ–‡æœ¬ä»¥åŠåŸå§‹æ–‡æœ¬è¡Œçš„DataFrame
      ä¿å­˜ä¸º `_8_2_DUBBING_TASK.xlsx`ï¼Œä¾›åç»­çš„TTSæ¨¡å—ä½¿ç”¨ã€‚

ä½¿ç”¨æ–¹æ³•:
  è¿è¡Œ `gen_dub_chunks()` å‡½æ•°ï¼Œå®ƒä¼šè¯»å– `_8_1_AUDIO_TASK.xlsx`ï¼Œæ‰§è¡Œåˆ†æå’Œåˆå¹¶ï¼Œ
  å¹¶ç”Ÿæˆæœ€ç»ˆçš„é…éŸ³ä»»åŠ¡å—æ–‡ä»¶ `_8_2_DUBBING_TASK.xlsx`ã€‚
"""

import datetime
import re
import pandas as pd
from core._8_1_audio_task import time_diff_seconds
from core.asr_backend.audio_preprocess import get_audio_duration
from core.tts_backend.estimate_duration import init_estimator, estimate_duration
from core.utils import *
from core.utils.models import *

# å®šä¹‰è¾“å…¥/è¾“å‡ºæ–‡ä»¶å’Œå¸¸é‡
SRC_SRT = "output/src.srt"
TRANS_SRT = "output/trans.srt"
MAX_MERGE_COUNT = 5  # å•æ¬¡åˆå¹¶çš„æœ€å¤§è¡Œæ•°
ESTIMATOR = None     # å…¨å±€æ—¶é•¿ä¼°ç®—å™¨å®ä¾‹

def calc_if_too_fast(est_dur: float, tol_dur: float, duration: float, tolerance: float) -> int:
    """
    è®¡ç®—è¯­é€ŸçŠ¶æ€æ ‡è®°ã€‚

    è¿”å›:
        int: 2 (æå¿«), 1 (åå¿«), 0 (æ­£å¸¸), -1 (åæ…¢)
    """
    accept_speed = load_key("speed_factor.accept")
    if est_dur / accept_speed > tol_dur:  # å³ä½¿åœ¨æœ€å¤§å¯æ¥å—è¯­é€Ÿä¸‹ä¹Ÿè¶…æ—¶
        return 2
    elif est_dur > tol_dur:  # éœ€è¦åœ¨å¯æ¥å—èŒƒå›´å†…åŠ é€Ÿ
        return 1
    elif est_dur < duration - tolerance:  # è¯­é€Ÿè¿‡æ…¢
        return -1
    else:  # è¯­é€Ÿæ­£å¸¸
        return 0

def merge_rows(df: pd.DataFrame, start_idx: int, merge_count: int) -> int:
    """
    ä» start_idx å¼€å§‹ï¼Œå‘ååˆå¹¶å¤šè¡Œå­—å¹•ï¼Œç›´åˆ°æ‰¾åˆ°ä¸€ä¸ªåˆé€‚çš„åˆ‡åˆ†ç‚¹ã€‚

    å‚æ•°:
        df (pd.DataFrame): åŒ…å«å­—å¹•ä¿¡æ¯çš„DataFrameã€‚
        start_idx (int): å¼€å§‹åˆå¹¶çš„è¡Œç´¢å¼•ã€‚
        merge_count (int): åˆå§‹åˆå¹¶è®¡æ•°ï¼ˆé€šå¸¸ä¸º1ï¼‰ã€‚

    è¿”å›:
        int: åˆå¹¶çš„æ€»è¡Œæ•°ã€‚
    """
    # åˆå§‹åŒ–åˆå¹¶åçš„ç´¯è®¡å€¼
    merged = {
        'est_dur': df.iloc[start_idx]['est_dur'],
        'tol_dur': df.iloc[start_idx]['tol_dur'],
        'duration': df.iloc[start_idx]['duration']
    }
    
    # å¾ªç¯åˆå¹¶ï¼Œç›´åˆ°è¾¾åˆ°ä¸Šé™æˆ–æ‰¾åˆ°åˆ‡ç‚¹
    while merge_count < MAX_MERGE_COUNT and (start_idx + merge_count) < len(df):
        next_row = df.iloc[start_idx + merge_count]
        merged['est_dur'] += next_row['est_dur']
        merged['tol_dur'] += next_row['tol_dur']
        merged['duration'] += next_row['duration']
        
        # é‡æ–°è®¡ç®—åˆå¹¶åçš„è¯­é€ŸçŠ¶æ€
        speed_flag = calc_if_too_fast(
            merged['est_dur'], merged['tol_dur'], merged['duration'],
            df.iloc[start_idx + merge_count]['tolerance']
        )
        
        # å¦‚æœè¯­é€Ÿæ­£å¸¸/åæ…¢ï¼Œæˆ–è¾¾åˆ°ä¸€å®šåˆå¹¶æ•°é‡ï¼Œåˆ™è®¾ç½®åˆ‡ç‚¹å¹¶è¿”å›
        if speed_flag <= 0 or merge_count == 2:
            df.at[start_idx + merge_count, 'cut_off'] = 1
            return merge_count + 1
        
        merge_count += 1
    
    # å¦‚æœå¾ªç¯ç»“æŸä»æœªæ‰¾åˆ°åˆ‡ç‚¹ï¼ˆä¾‹å¦‚ï¼Œä¸€ç›´è¿‡å¿«ï¼‰ï¼Œåˆ™åœ¨æœ€ååˆå¹¶çš„ä½ç½®å¼ºåˆ¶åˆ‡åˆ†
    if merge_count >= MAX_MERGE_COUNT or (start_idx + merge_count) >= len(df):
        df.at[start_idx + merge_count - 1, 'cut_off'] = 1
    return merge_count

def analyze_subtitle_timing_and_speed(df: pd.DataFrame) -> pd.DataFrame:
    """åˆ†æå­—å¹•æ—¶åºã€è®¡ç®—é—´éš™ã€å®¹å¿æ—¶é•¿ã€é¢„ä¼°æœ—è¯»æ—¶é•¿å’Œè¯­é€ŸçŠ¶æ€ã€‚"""
    rprint("[ğŸ” åˆ†æ] æ­£åœ¨è®¡ç®—å­—å¹•æ—¶åºå’Œè¯­é€Ÿ...")
    global ESTIMATOR
    if ESTIMATOR is None: ESTIMATOR = init_estimator()
    
    TOLERANCE = load_key("tolerance")
    whole_dur = get_audio_duration(_RAW_AUDIO_FILE)
    
    # è®¡ç®—æ¯è¡Œå­—å¹•åçš„é—´éš™æ—¶é—´
    df['gap'] = 0.0
    df['end_time_dt'] = pd.to_datetime(df['end_time_str'], format='%H:%M:%S,%f').dt.time
    df['start_time_dt'] = pd.to_datetime(df['start_time_str'], format='%H:%M:%S,%f').dt.time
    
    for i in range(len(df) - 1):
        df.loc[i, 'gap'] = time_diff_seconds(df.loc[i, 'end_time_dt'], df.loc[i + 1, 'start_time_dt'], datetime.date.today())
    
    last_end_seconds = df.iloc[-1]['end_time_dt'].hour * 3600 + df.iloc[-1]['end_time_dt'].minute * 60 + df.iloc[-1]['end_time_dt'].second + df.iloc[-1]['end_time_dt'].microsecond / 1e6
    df.iloc[-1, df.columns.get_loc('gap')] = whole_dur - last_end_seconds
    
    # è®¡ç®—å®¹å¿æ—¶é•¿å’Œé¢„ä¼°æœ—è¯»æ—¶é•¿
    df['tolerance'] = df['gap'].apply(lambda x: min(x, TOLERANCE))
    df['tol_dur'] = df['duration'] + df['tolerance']
    df['est_dur'] = df.apply(lambda x: estimate_duration(x['text'], ESTIMATOR), axis=1)

    # è®¡ç®—è¯­é€ŸçŠ¶æ€æ ‡è®°
    df['if_too_fast'] = df.apply(lambda row: calc_if_too_fast(row['est_dur'], row['tol_dur'], row['duration'], row['tolerance']), axis=1)
    return df.drop(columns=['end_time_dt', 'start_time_dt'])

def process_cutoffs(df: pd.DataFrame) -> pd.DataFrame:
    """æ ¹æ®è¯­é€ŸçŠ¶æ€å’Œåˆå¹¶é€»è¾‘ï¼Œç”Ÿæˆæœ€ç»ˆçš„åˆ‡åˆ†ç‚¹ã€‚"""
    rprint("[âœ‚ï¸ å¤„ç†] æ­£åœ¨ç”Ÿæˆåˆ‡åˆ†ç‚¹...")
    df['cut_off'] = 0
    df.loc[df['gap'] >= load_key("tolerance"), 'cut_off'] = 1  # ä¼˜å…ˆåœ¨é•¿é—´éš™å¤„åˆ‡åˆ†
    
    idx = 0
    while idx < len(df):
        if df.iloc[idx]['cut_off'] == 1:
            if df.iloc[idx]['if_too_fast'] == 2:
                rprint(f"[âš ï¸ è­¦å‘Š] ç¬¬ {idx} è¡Œè¯­é€Ÿæå¿«ï¼Œæ— æ³•é€šè¿‡è°ƒé€Ÿä¿®å¤ã€‚")
            idx += 1
            continue

        if idx + 1 >= len(df):
            df.at[idx, 'cut_off'] = 1; break

        if df.iloc[idx]['if_too_fast'] <= 0: # å½“å‰è¡Œè¯­é€Ÿæ­£å¸¸æˆ–åæ…¢
            if df.iloc[idx + 1]['if_too_fast'] <= 0: # ä¸‹ä¸€è¡Œä¹Ÿæ­£å¸¸æˆ–åæ…¢
                df.at[idx, 'cut_off'] = 1 # å½“å‰è¡Œå¯ç‹¬ç«‹æˆå—
                idx += 1
            else: # ä¸‹ä¸€è¡Œåå¿«ï¼Œéœ€è¦åˆå¹¶
                idx += merge_rows(df, idx, 1)
        else: # å½“å‰è¡Œåå¿«ï¼Œéœ€è¦åˆå¹¶
            idx += merge_rows(df, idx, 1)
    
    return df

@check_file_exists(_8_2_DUBBING_TASK)
def dub_chunks_main():
    """ä¸»å‡½æ•°ï¼šç”Ÿæˆæœ€ç»ˆçš„é…éŸ³ä»»åŠ¡å—ã€‚"""
    console.print(Panel("[bold cyan]ğŸ§  å¼€å§‹ç”Ÿæˆæ™ºèƒ½é…éŸ³å—...[/bold cyan]", title="ç¬¬å…«æ­¥ (2/2): ä¼˜åŒ–é…éŸ³åˆ†å—", expand=False))

    # æ­¥éª¤ 1: åŠ è½½åˆçº§ä»»åŠ¡
    console.print(f"[cyan]- æ­¥éª¤ 1/4: æ­£åœ¨ä» `{_8_1_AUDIO_TASK}` åŠ è½½éŸ³é¢‘ä»»åŠ¡...[/cyan]")
    df = pd.read_excel(_8_1_AUDIO_TASK)
    console.print(f"[green]  âœ… åŠ è½½å®Œæˆï¼Œå…± {len(df)} æ¡åˆçº§ä»»åŠ¡ã€‚[/green]")

    # æ­¥éª¤ 2: åˆ†ææ—¶åºä¸è¯­é€Ÿ
    console.print("[cyan]- æ­¥éª¤ 2/4: æ­£åœ¨è¿›è¡Œæ—¶åºä¸è¯­é€Ÿåˆ†æ...[/cyan]")
    df = analyze_subtitle_timing_and_speed(df)
    fast_count = len(df[df['if_too_fast'] > 0])
    console.print(f"[green]  âœ… åˆ†æå®Œæˆï¼Œè¯†åˆ«å‡º {fast_count} æ¡è¯­é€Ÿå¯èƒ½è¿‡å¿«çš„å­—å¹•ã€‚[/green]")

    # æ­¥éª¤ 3: æ™ºèƒ½åˆå¹¶ä¸åˆ‡åˆ†
    console.print("[cyan]- æ­¥éª¤ 3/4: æ­£åœ¨æ™ºèƒ½åˆå¹¶å­—å¹•ä»¥ä¼˜åŒ–è¯­é€Ÿ...[/cyan]")
    df = process_cutoffs(df)
    final_df = df[df['cut_off'] == 1].copy()
    console.print(f"[green]  âœ… åˆå¹¶å®Œæˆï¼Œç”Ÿæˆ {len(final_df)} ä¸ªæœ€ç»ˆé…éŸ³å—ã€‚[/green]")

    # æ­¥éª¤ 4: åŒ¹é…åŸå§‹æ–‡æœ¬å¹¶ä¿å­˜
    console.print("[cyan]- æ­¥éª¤ 4/4: æ­£åœ¨åŒ¹é…åŸå§‹æ–‡æœ¬å¹¶ä¿å­˜æœ€ç»ˆä»»åŠ¡æ¸…å•...[/cyan]")
    with open(TRANS_SRT, "r", encoding="utf-8") as f: content = f.read()
    with open(SRC_SRT, "r", encoding="utf-8") as f: ori_content = f.read()
    
    def get_lines_from_srt(srt_content):
        lines_list = []
        for block in srt_content.strip().split('\n\n'):
            lines = [line.strip() for line in block.split('\n') if line.strip()]
            if len(lines) >= 3:
                text = ' '.join(lines[2:])
                text = re.sub(r'\([^)]*\)|ï¼ˆ[^ï¼‰]*ï¼‰', '', text).strip().replace('-', '')
                lines_list.append(text)
        return lines_list

    content_lines = get_lines_from_srt(content)
    ori_content_lines = get_lines_from_srt(ori_content)

    final_df['lines'] = None
    final_df['src_lines'] = None
    last_idx = 0

    def clean_text(text):
        return re.sub(r'[^\w\s]|\s', '', str(text)) if text else ''

    # é‡ç½®ç´¢å¼•ä»¥ä¾¿äºéå†
    final_df.reset_index(drop=True, inplace=True)
    temp_df = df.copy()
    temp_df.reset_index(drop=True, inplace=True)
    original_indices = final_df['number'].apply(lambda x: temp_df[temp_df['number'] == x].index[0])

    for i, (final_idx, row) in enumerate(final_df.iterrows()):
        start_original_idx = original_indices[i]
        if i + 1 < len(original_indices):
            end_original_idx = original_indices[i+1]
        else:
            end_original_idx = len(df)
        
        merged_rows = df.iloc[start_original_idx:end_original_idx]
        
        lines_to_match = list(merged_rows['number'] - 1) # srt number is 1-based
        final_df.at[final_idx, 'lines'] = [content_lines[j] for j in lines_to_match]
        final_df.at[final_idx, 'src_lines'] = [ori_content_lines[j] for j in lines_to_match]

    final_df.to_excel(_8_2_DUBBING_TASK, index=False)
    console.print(Panel(f"[bold green]ğŸ‰ æ™ºèƒ½é…éŸ³å—ç”ŸæˆæˆåŠŸï¼[/bold green]", subtitle=f"æœ€ç»ˆä»»åŠ¡æ–‡ä»¶å·²ä¿å­˜è‡³: {_8_2_DUBBING_TASK}", expand=False))

if __name__ == '__main__':
    dub_chunks_main()