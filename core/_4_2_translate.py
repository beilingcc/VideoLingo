# -*- coding: utf-8 -*-
"""
å¹¶è¡Œç¿»è¯‘æ¨¡å—

æœ¬æ¨¡å—è´Ÿè´£å°†ç»è¿‡è¯­ä¹‰åˆ†å‰²çš„æ–‡æœ¬å—è¿›è¡Œé«˜æ•ˆçš„å¹¶è¡Œç¿»è¯‘ã€‚å…¶è®¾è®¡æ—¨åœ¨æœ€å¤§åŒ–ç¿»è¯‘æ•ˆç‡ï¼Œ
åŒæ—¶é€šè¿‡ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ¥ä¿è¯ç¿»è¯‘è´¨é‡å’Œè¿è´¯æ€§ã€‚

æ ¸å¿ƒåŠŸèƒ½:
1.  **æ–‡æœ¬åˆ†å— (Chunking)**:
    - `split_chunks_by_chars`: å°†å®Œæ•´çš„æ–‡æœ¬ï¼ˆæ¥è‡ª `_3_2_SPLIT_BY_MEANING` çš„è¾“å‡ºï¼‰
      æŒ‰ç…§æŒ‡å®šçš„å­—ç¬¦æ•°å’Œæœ€å¤§è¡Œæ•°åˆ†å‰²æˆé€‚åˆå¹¶è¡Œå¤„ç†çš„æ–‡æœ¬å—ï¼ˆchunksï¼‰ã€‚
      è¿™æ ·åšæ˜¯ä¸ºäº†å¹³è¡¡ API è°ƒç”¨å¼€é”€å’Œä¸Šä¸‹æ–‡é•¿åº¦ï¼Œé¿å…å•ä¸ªè¯·æ±‚è¿‡å¤§æˆ–è¿‡å°ã€‚

2.  **ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç¿»è¯‘ (Context-Aware Translation)**:
    - `get_previous_content` / `get_after_content`: ä¸ºæ¯ä¸ªå¾…ç¿»è¯‘çš„æ–‡æœ¬å—æå–å…¶
      å‰å‡ è¡Œå’Œåå‡ è¡Œçš„å†…å®¹ä½œä¸ºä¸Šä¸‹æ–‡ã€‚è¿™å¯¹äºå¤„ç†è·¨è¶Šå¤šè¡Œçš„å¥å­ã€è§£å†³ä»£è¯æŒ‡ä»£
      ä¸æ¸…ç­‰é—®é¢˜è‡³å…³é‡è¦ï¼Œèƒ½æ˜¾è‘—æå‡ç¿»è¯‘çš„è¿è´¯æ€§å’Œå‡†ç¡®æ€§ã€‚
    - `translate_chunk`: å•ä¸ªæ–‡æœ¬å—çš„ç¿»è¯‘å•å…ƒã€‚å®ƒæ•´åˆäº†åŸæ–‡ã€ä¸Šä¸‹æ–‡ã€ä»¥åŠä»
      `_4_1_summarize` æ¨¡å—è·å–çš„ä¸»é¢˜å’Œæœ¯è¯­è¡¨ï¼Œç„¶åè°ƒç”¨ `translate_lines` å‡½æ•°
      ï¼ˆé€šå¸¸æ˜¯ä¸ LLM API äº¤äº’çš„å°è£…ï¼‰æ¥è·å–ç¿»è¯‘ç»“æœã€‚

3.  **å¹¶è¡Œå¤„ç† (Concurrent Execution)**:
    - åˆ©ç”¨ `concurrent.futures.ThreadPoolExecutor` å®ç°å¯¹å¤šä¸ªæ–‡æœ¬å—çš„å¹¶è¡Œç¿»è¯‘è¯·æ±‚ã€‚
      è¿™æå¤§åœ°ç¼©çŸ­äº†æ€»ç¿»è¯‘æ—¶é—´ï¼Œç‰¹åˆ«æ˜¯å¯¹äºé•¿è§†é¢‘ã€‚
    - `max_workers` å‚æ•°å¯ä»¥ä»é…ç½®ä¸­åŠ è½½ï¼Œå…è®¸ç”¨æˆ·æ ¹æ®è‡ªå·±çš„ç½‘ç»œå’Œ API é™åˆ¶
      æ¥è°ƒæ•´å¹¶å‘çº§åˆ«ã€‚

4.  **ç»“æœæ•´åˆä¸æ ¡éªŒ (Result Integration and Validation)**:
    - `similar`: ä½¿ç”¨ `difflib.SequenceMatcher` è®¡ç®—åŸæ–‡å—å’Œè¿”å›çš„ç¿»è¯‘ç»“æœä¸­åŸæ–‡éƒ¨åˆ†
      çš„ç›¸ä¼¼åº¦ã€‚è¿™æ˜¯ä¸€ä¸ªå…³é”®çš„æ ¡éªŒæ­¥éª¤ï¼Œç”¨äºç¡®ä¿ LLM è¿”å›çš„ç»“æœä¸æˆ‘ä»¬å‘é€çš„è¯·æ±‚
      æ˜¯æ­£ç¡®å¯¹åº”çš„ï¼Œé˜²æ­¢å›  API é—®é¢˜æˆ–å¹¶å‘å¤„ç†å¯¼è‡´çš„æ•°æ®é”™ä¹±ã€‚
    - åœ¨æ”¶é›†å®Œæ‰€æœ‰å¹¶è¡Œä»»åŠ¡çš„ç»“æœåï¼ŒæŒ‰åŸå§‹é¡ºåºæ’åºï¼Œå¹¶é€šè¿‡ç›¸ä¼¼åº¦åŒ¹é…å°†ç¿»è¯‘
      ç»“æœä¸åŸæ–‡å—ä¸€ä¸€å¯¹åº”ã€‚å¦‚æœç›¸ä¼¼åº¦ä½äºé˜ˆå€¼ï¼Œå°†æŠ›å‡ºå¼‚å¸¸ï¼Œé˜²æ­¢é”™è¯¯çš„ç¿»è¯‘
      å†…å®¹è¿›å…¥åç»­æµç¨‹ã€‚

5.  **æ—¶é—´æˆ³å¯¹é½ä¸åå¤„ç† (Timestamp Alignment and Post-processing)**:
    - `align_timestamp`: å°†ç¿»è¯‘å¥½çš„æ–‡æœ¬ä¸åŸå§‹çš„å¸¦æ—¶é—´æˆ³çš„ ASR ç»“æœè¿›è¡Œå¯¹é½ï¼Œ
      ç”Ÿæˆç”¨äºåˆ¶ä½œå­—å¹•çš„ SRT æ–‡ä»¶æ ¼å¼æ‰€éœ€çš„æ•°æ®ç»“æ„ã€‚
    - `check_len_then_trim`: å¯¹ç¿»è¯‘åçš„æ–‡æœ¬è¿›è¡Œé•¿åº¦æ£€æŸ¥ï¼Œå¦‚æœè¯‘æ–‡ç›¸å¯¹äºå…¶
      å¯¹åº”çš„æ—¶é—´æˆ³è¿‡é•¿ï¼Œä¼šè¿›è¡Œæ™ºèƒ½è£å‰ªï¼Œä»¥ä¿è¯å­—å¹•çš„æ˜¾ç¤ºæ•ˆæœã€‚

6.  **ç»“æœä¿å­˜ (Saving Results)**:
    - æœ€ç»ˆå°†åŒ…å«åŸæ–‡ã€è¯‘æ–‡å’Œæ—¶é—´æˆ³çš„ DataFrame ä¿å­˜åˆ° Excel æ–‡ä»¶
      (`_4_2_TRANSLATION`) ä¸­ï¼Œä¾›åç»­ç”ŸæˆéŸ³é¢‘å’Œè§†é¢‘çš„æ¨¡å—ä½¿ç”¨ã€‚

ä½¿ç”¨æ–¹æ³•:
  è¿è¡Œ `translate_all()` å‡½æ•°å³å¯å¯åŠ¨æ•´ä¸ªç¿»è¯‘æµç¨‹ã€‚è¿™æ˜¯ä¸€ä¸ªè‡ªåŠ¨åŒ–çš„ã€ç«¯åˆ°ç«¯çš„
  ç¿»è¯‘æ­¥éª¤ï¼Œæ˜¯æ•´ä¸ªè§†é¢‘ç¿»è¯‘æµç¨‹ä¸­çš„æ ¸å¿ƒç¯èŠ‚ã€‚
"""

import pandas as pd
import json
import concurrent.futures
from difflib import SequenceMatcher
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn

from core.translate_lines import translate_lines
from core._8_1_audio_task import check_len_then_trim
from core._6_gen_sub import align_timestamp
from core.utils import *
from core.utils.models import *

console = Console()

def split_chunks_by_chars(chunk_size: int, max_i: int) -> list[str]:
    """
    æ ¹æ®å­—ç¬¦æ•°å’Œæœ€å¤§è¡Œæ•°å°†æ–‡æœ¬åˆ†å‰²æˆå—ã€‚
    """
    with open(_3_2_SPLIT_BY_MEANING, "r", encoding="utf-8") as file:
        sentences = file.read().strip().split('\n')

    chunks = []
    current_chunk = ''
    sentence_count = 0
    for sentence in sentences:
        if len(current_chunk) + len(sentence + '\n') > chunk_size or sentence_count >= max_i:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = sentence + '\n'
            sentence_count = 1
        else:
            current_chunk += sentence + '\n'
            sentence_count += 1
    if current_chunk:
        chunks.append(current_chunk.strip())
    return chunks

def get_previous_content(chunks: list[str], chunk_index: int) -> list[str] or None:
    """è·å–å½“å‰å—ä¹‹å‰çš„å†…å®¹ä½œä¸ºä¸Šä¸‹æ–‡ï¼ˆå‰3è¡Œï¼‰ã€‚"""
    if chunk_index == 0:
        return None
    return chunks[chunk_index - 1].split('\n')[-3:]

def get_after_content(chunks: list[str], chunk_index: int) -> list[str] or None:
    """è·å–å½“å‰å—ä¹‹åçš„å†…å®¹ä½œä¸ºä¸Šä¸‹æ–‡ï¼ˆå2è¡Œï¼‰ã€‚"""
    if chunk_index >= len(chunks) - 1:
        return None
    return chunks[chunk_index + 1].split('\n')[:2]

def translate_chunk(chunk: str, chunks: list[str], theme_prompt: str, terms: list[dict], i: int) -> tuple[int, str, str]:
    """
    ç¿»è¯‘å•ä¸ªæ–‡æœ¬å—ï¼Œå¹¶æ•´åˆä¸Šä¸‹æ–‡ä¿¡æ¯å’Œæœ¯è¯­æç¤ºã€‚
    """
    # ä»é¢„åŠ è½½çš„æœ¯è¯­åˆ—è¡¨ä¸­æœç´¢éœ€è¦ç‰¹åˆ«æ³¨æ„çš„æœ¯è¯­
    things_to_note_list = [term for term in terms if term.get('src', '').lower() in chunk.lower()]
    things_to_note_prompt = None
    if things_to_note_list:
        things_to_note_prompt = '\n'.join(
            f'{idx+1}. "{term["src"]}": "{term["tgt"]}", meaning: {term["note"]}'
            for idx, term in enumerate(things_to_note_list)
        )
    
    previous_content_prompt = get_previous_content(chunks, i)
    after_content_prompt = get_after_content(chunks, i)
    
    translation, english_result = translate_lines(chunk, previous_content_prompt, after_content_prompt, things_to_note_prompt, theme_prompt, i)
    return i, english_result, translation

def similar(a: str, b: str) -> float:
    """è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦ã€‚"""
    return SequenceMatcher(None, a, b).ratio()

@check_file_exists(_4_2_TRANSLATION)
def translate_main():
    """
    æ‰§è¡Œæ‰€æœ‰æ–‡æœ¬å—çš„ç¿»è¯‘ä¸»æµç¨‹ã€‚
    """
    console.print(Panel("ğŸš€ [bold cyan]å¯åŠ¨å¹¶è¡Œç¿»è¯‘æµç¨‹[/bold cyan]", 
                        title="[bold]æ­¥éª¤ 4.2[/bold]", subtitle="[bold]å¹¶è¡Œç¿»è¯‘[/bold]", expand=False))
    try:
        # æ­¥éª¤ 1: æ–‡æœ¬åˆ†å—
        console.log("æ­¥éª¤ 1/6: æ­£åœ¨å°†æ–‡æœ¬åˆ†å‰²æˆé€‚åˆç¿»è¯‘çš„å—...")
        chunks = split_chunks_by_chars(chunk_size=600, max_i=10)
        console.log(f"[green]  âœ“ æ–‡æœ¬å·²æˆåŠŸåˆ†å‰²æˆ {len(chunks)} ä¸ªå—ã€‚[/green]")

        # æ­¥éª¤ 2: åŠ è½½æœ¯è¯­å’Œä¸»é¢˜
        console.log("æ­¥éª¤ 2/6: æ­£åœ¨åŠ è½½æœ¯è¯­è¡¨å’Œä¸»é¢˜æç¤º...")
        with open(_4_1_TERMINOLOGY, 'r', encoding='utf-8') as file:
            terminology_data = json.load(file)
            theme_prompt = terminology_data.get('theme')
            terms_list = terminology_data.get('terms', [])
        console.log(f"[green]  âœ“ æœ¯è¯­è¡¨åŠ è½½å®Œæˆã€‚[/green]")

        # æ­¥éª¤ 3: å¹¶è¡Œç¿»è¯‘
        console.log(f"æ­¥éª¤ 3/6: æ­£åœ¨å¯åŠ¨å¹¶è¡Œç¿»è¯‘... (å…± {len(chunks)} ä¸ªä»»åŠ¡)")
        results = []
        with Progress(SpinnerColumn(), TextColumn("[progress.description]{task.description}{task.percentage:>3.0f}%"), transient=False) as progress:
            task = progress.add_task("[cyan]ç¿»è¯‘ä¸­...[/cyan]", total=len(chunks))
            with concurrent.futures.ThreadPoolExecutor(max_workers=load_key("max_workers")) as executor:
                futures = [executor.submit(translate_chunk, chunk, chunks, theme_prompt, terms_list, i) for i, chunk in enumerate(chunks)]
                
                for future in concurrent.futures.as_completed(futures):
                    results.append(future.result())
                    progress.update(task, advance=1)
        console.log(f"[green]  âœ“ æ‰€æœ‰ç¿»è¯‘ä»»åŠ¡å·²å®Œæˆã€‚[/green]")

        # æ­¥éª¤ 4: ç»“æœæ’åºä¸æ ¡éªŒ
        console.log("æ­¥éª¤ 4/6: æ­£åœ¨å¯¹ç¿»è¯‘ç»“æœè¿›è¡Œæ’åºå’Œæ ¡éªŒ...")
        results.sort(key=lambda x: x[0])
        
        src_text, trans_text = [], []
        for i, chunk in enumerate(chunks):
            chunk_lines = chunk.split('\n')
            src_text.extend(chunk_lines)
            
            chunk_text_lower = ''.join(chunk_lines).lower()
            matching_results = [(r, similar(''.join(r[1].split('\n')).lower(), chunk_text_lower)) for r in results]
            best_match = max(matching_results, key=lambda x: x[1])
            
            if best_match[1] < 0.9:
                raise ValueError(f"ç¿»è¯‘åŒ¹é…å¤±è´¥ (å— {i})ï¼Œæœ€ä½³åŒ¹é…ç›¸ä¼¼åº¦: {best_match[1]:.3f}")
            elif best_match[1] < 0.99:
                console.log(f"[yellow]  âš ï¸ è­¦å‘Š: æ‰¾åˆ°å— {i} çš„è¿‘ä¼¼åŒ¹é… (ç›¸ä¼¼åº¦: {best_match[1]:.3f})[/yellow]")
                
            trans_text.extend(best_match[0][2].split('\n'))
        console.log("[green]  âœ“ ç»“æœæ ¡éªŒæˆåŠŸï¼Œæ‰€æœ‰ç¿»è¯‘å—å‡å·²æ­£ç¡®åŒ¹é…ã€‚[/green]")

        # æ­¥éª¤ 5: æ—¶é—´æˆ³å¯¹é½ä¸è¯‘æ–‡è£å‰ª
        console.log("æ­¥éª¤ 5/6: æ­£åœ¨è¿›è¡Œæ—¶é—´æˆ³å¯¹é½å’Œè¯‘æ–‡é•¿åº¦è£å‰ª...")
        df_text = pd.read_excel(_2_CLEANED_CHUNKS)
        df_text['text'] = df_text['text'].str.strip('"').str.strip()
        df_translate = pd.DataFrame({'Source': src_text, 'Translation': trans_text})
        
        subtitle_output_configs = [('trans_subs_for_audio.srt', ['Translation'])]
        df_time = align_timestamp(df_text, df_translate, subtitle_output_configs, output_dir=None, for_display=False)
        
        df_time['Translation'] = df_time.apply(
            lambda row: check_len_then_trim(row['Translation'], row['duration']) 
            if row['duration'] > load_key("min_trim_duration") else row['Translation'], 
            axis=1
        )
        console.log("[green]  âœ“ æ—¶é—´æˆ³å¯¹é½å’Œè¯‘æ–‡è£å‰ªå®Œæˆã€‚[/green]")

        # æ­¥éª¤ 6: ä¿å­˜æœ€ç»ˆç»“æœ
        console.log("æ­¥éª¤ 6/6: æ­£åœ¨ä¿å­˜æœ€ç»ˆç¿»è¯‘ç»“æœ...")
        df_time.to_excel(_4_2_TRANSLATION, index=False)
        console.print(Panel(f"âœ… [bold green]ç¿»è¯‘æµç¨‹å…¨éƒ¨å®Œæˆï¼[/bold green]\nç»“æœå·²ä¿å­˜è‡³ '{_4_2_TRANSLATION}'", 
                            title="[bold green]æˆåŠŸ[/bold green]", expand=True))

    except Exception as e:
        console.print(Panel(f"ç¿»è¯‘è¿‡ç¨‹ä¸­å‘ç”Ÿæ„å¤–é”™è¯¯: {e}", title="[bold red]é”™è¯¯[/bold red]", expand=True))
        raise

if __name__ == '__main__':
    translate_main()