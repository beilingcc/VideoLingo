# å¯¼å…¥æ‰€éœ€åº“
import streamlit as st  # ç”¨äºåˆ›å»ºWebåº”ç”¨ç•Œé¢
from translations.translations import translate as t, DISPLAY_LANGUAGES  # å¯¼å…¥ç¿»è¯‘å‡½æ•°å’Œæ”¯æŒçš„æ˜¾ç¤ºè¯­è¨€
from core.utils import *  # å¯¼å…¥æ‰€æœ‰è‡ªå®šä¹‰å·¥å…·å‡½æ•°

def config_input(label, key, help=None):
    """
    ä¸€ä¸ªé€šç”¨çš„Streamlitæ–‡æœ¬è¾“å…¥æ¡†å¤„ç†å‡½æ•°ï¼Œç”¨äºæ›´æ–°é…ç½®æ–‡ä»¶ã€‚

    å½“è¾“å…¥æ¡†çš„å€¼å‘ç”Ÿæ”¹å˜æ—¶ï¼Œä¼šè‡ªåŠ¨è°ƒç”¨`update_key`æ¥ä¿å­˜æ–°å€¼ã€‚

    Args:
        label (str): è¾“å…¥æ¡†çš„æ ‡ç­¾ã€‚
        key (str): åœ¨é…ç½®æ–‡ä»¶ä¸­å¯¹åº”çš„é”®ã€‚
        help (str, optional): è¾“å…¥æ¡†çš„å¸®åŠ©æç¤ºæ–‡æœ¬ã€‚ Defaults to None.

    Returns:
        str: è¾“å…¥æ¡†å½“å‰çš„å€¼ã€‚
    """
    # ä»é…ç½®æ–‡ä»¶åŠ è½½å½“å‰å€¼
    current_value = load_key(key)
    # åˆ›å»ºæ–‡æœ¬è¾“å…¥æ¡†
    new_value = st.text_input(label, value=current_value, help=help)
    # å¦‚æœå€¼æœ‰å˜åŒ–ï¼Œåˆ™æ›´æ–°é…ç½®æ–‡ä»¶
    if new_value != current_value:
        update_key(key, new_value)
        # å¯èƒ½éœ€è¦é‡æ–°è¿è¡Œä»¥åº”ç”¨æ›´æ”¹ï¼Œä½†ä¸ºé¿å…ä¸å¿…è¦çš„åˆ·æ–°ï¼Œæ­¤å¤„æ³¨é‡Šæ‰
        # st.rerun()
    return new_value

def page_setting():
    """
    åœ¨Streamlitä¾§è¾¹æ ä¸­æ¸²æŸ“æ‰€æœ‰çš„é¡µé¢è®¾ç½®é€‰é¡¹ã€‚
    åŒ…æ‹¬è¯­è¨€ã€LLMã€å­—å¹•å’Œé…éŸ³ç­‰ç›¸å…³é…ç½®ã€‚
    """

    # --- æ˜¾ç¤ºè¯­è¨€è®¾ç½® ---
    st.selectbox(
        "Display Language ğŸŒ", 
        options=list(DISPLAY_LANGUAGES.keys()),
        index=list(DISPLAY_LANGUAGES.values()).index(load_key("display_language")),
        key="display_language_selector"
    )
    selected_lang_code = DISPLAY_LANGUAGES[st.session_state.display_language_selector]
    if selected_lang_code != load_key("display_language"):
        update_key("display_language", selected_lang_code)
        st.rerun()  # è¯­è¨€æ›´æ”¹åç«‹å³åˆ·æ–°ç•Œé¢

    # --- å¤§è¯­è¨€æ¨¡å‹ (LLM) é…ç½® ---
    with st.expander(t("LLM Configuration"), expanded=True):
        config_input(t("API_KEY"), "api.key")
        config_input(t("BASE_URL"), "api.base_url", help=t("Openai format, will add /v1/chat/completions automatically"))
        
        col1, col2 = st.columns([4, 1])
        with col1:
            config_input(t("MODEL"), "api.model", help=t("click to check API validity") + " ğŸ‘‰")
        with col2:
            # APIæœ‰æ•ˆæ€§æ£€æŸ¥æŒ‰é’®
            if st.button("ğŸ“¡", key="api_check_button"):
                is_valid = check_api()
                st.toast(
                    t("API Key is valid") if is_valid else t("API Key is invalid"), 
                    icon="âœ…" if is_valid else "âŒ"
                )
        
        # LLMæ˜¯å¦æ”¯æŒJSONæ ¼å¼è¾“å‡ºçš„å¼€å…³
        llm_support_json = st.toggle(t("LLM JSON Format Support"), value=load_key("api.llm_support_json"), help=t("Enable if your LLM supports JSON mode output"))
        if llm_support_json != load_key("api.llm_support_json"):
            update_key("api.llm_support_json", llm_support_json)
            st.rerun()

    # --- å­—å¹•è®¾ç½® ---
    with st.expander(t("Subtitles Settings"), expanded=True):
        col1, col2 = st.columns(2)
        with col1:
            # è¯­éŸ³è¯†åˆ«è¯­è¨€é€‰æ‹©
            recog_langs = {
                "ğŸ‡ºğŸ‡¸ English": "en", "ğŸ‡¨ğŸ‡³ ç®€ä½“ä¸­æ–‡": "zh", "ğŸ‡ªğŸ‡¸ EspaÃ±ol": "es",
                "ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹": "ru", "ğŸ‡«ğŸ‡· FranÃ§ais": "fr", "ğŸ‡©ğŸ‡ª Deutsch": "de",
                "ğŸ‡®ğŸ‡¹ Italiano": "it", "ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª": "ja"
            }
            selected_recog_lang = st.selectbox(
                t("Recog Lang"),
                options=list(recog_langs.keys()),
                index=list(recog_langs.values()).index(load_key("whisper.language"))
            )
            if recog_langs[selected_recog_lang] != load_key("whisper.language"):
                update_key("whisper.language", recog_langs[selected_recog_lang])
                st.rerun()

        # WhisperXè¿è¡Œç¯å¢ƒé€‰æ‹© (æœ¬åœ°/äº‘ç«¯/ElevenLabs)
        runtime = st.selectbox(t("WhisperX Runtime"), options=["local", "cloud", "elevenlabs"], index=["local", "cloud", "elevenlabs"].index(load_key("whisper.runtime")), help=t("Local runtime requires >8GB GPU, cloud runtime requires 302ai API key, elevenlabs runtime requires ElevenLabs API key"))
        if runtime != load_key("whisper.runtime"):
            update_key("whisper.runtime", runtime)
            st.rerun()
        # æ ¹æ®ä¸åŒçš„è¿è¡Œç¯å¢ƒï¼Œæ˜¾ç¤ºå¯¹åº”çš„API Keyè¾“å…¥æ¡†
        if runtime == "cloud":
            config_input(t("WhisperX 302ai API"), "whisper.whisperX_302_api_key")
        elif runtime == "elevenlabs":
            config_input(t("ElevenLabs API"), "whisper.elevenlabs_api_key")

        with col2:
            # ç›®æ ‡ç¿»è¯‘è¯­è¨€è¾“å…¥
            target_language = st.text_input(t("Target Lang"), value=load_key("target_language"), help=t("Input any language in natural language, as long as llm can understand"))
            if target_language != load_key("target_language"):
                update_key("target_language", target_language)
                st.rerun()

        # äººå£°åˆ†ç¦»å¢å¼ºå¼€å…³
        demucs = st.toggle(t("Vocal separation enhance"), value=load_key("demucs"), help=t("Recommended for videos with loud background noise, but will increase processing time"))
        if demucs != load_key("demucs"):
            update_key("demucs", demucs)
            st.rerun()
        
        # çƒ§å½•å­—å¹•å¼€å…³
        burn_subtitles = st.toggle(t("Burn-in Subtitles"), value=load_key("burn_subtitles"), help=t("Whether to burn subtitles into the video, will increase processing time"))
        if burn_subtitles != load_key("burn_subtitles"):
            update_key("burn_subtitles", burn_subtitles)
            st.rerun()

    # --- é…éŸ³è®¾ç½® ---
    with st.expander(t("Dubbing Settings"), expanded=True):
        tts_methods = ["azure_tts", "openai_tts", "fish_tts", "sf_fish_tts", "edge_tts", "gpt_sovits", "custom_tts", "sf_cosyvoice2", "f5tts"]
        select_tts = st.selectbox(t("TTS Method"), options=tts_methods, index=tts_methods.index(load_key("tts_method")))
        if select_tts != load_key("tts_method"):
            update_key("tts_method", select_tts)
            st.rerun()

        # --- ä¸åŒTTSæ–¹æ³•çš„å­è®¾ç½® ---
        if select_tts == "sf_fish_tts":
            config_input(t("SiliconFlow API Key"), "sf_fish_tts.api_key")
            mode_options = {"preset": t("Preset"), "custom": t("Refer_stable"), "dynamic": t("Refer_dynamic")}
            selected_mode = st.selectbox(t("Mode Selection"), options=list(mode_options.keys()), format_func=lambda x: mode_options[x], index=list(mode_options.keys()).index(load_key("sf_fish_tts.mode")) if load_key("sf_fish_tts.mode") in mode_options.keys() else 0)
            if selected_mode != load_key("sf_fish_tts.mode"):
                update_key("sf_fish_tts.mode", selected_mode)
                st.rerun()
            if selected_mode == "preset":
                config_input("Voice", "sf_fish_tts.voice")

        elif select_tts == "openai_tts":
            config_input("302ai API", "openai_tts.api_key")
            config_input(t("OpenAI Voice"), "openai_tts.voice")

        elif select_tts == "fish_tts":
            config_input("302ai API", "fish_tts.api_key")
            character_dict = load_key("fish_tts.character_id_dict")
            fish_tts_character = st.selectbox(t("Fish TTS Character"), options=list(character_dict.keys()), index=list(character_dict.keys()).index(load_key("fish_tts.character")))
            if fish_tts_character != load_key("fish_tts.character"):
                update_key("fish_tts.character", fish_tts_character)
                st.rerun()

        elif select_tts == "azure_tts":
            config_input("302ai API", "azure_tts.api_key")
            config_input(t("Azure Voice"), "azure_tts.voice")
        
        elif select_tts == "gpt_sovits":
            st.info(t("Please refer to Github homepage for GPT_SoVITS configuration"))
            config_input(t("SoVITS Character"), "gpt_sovits.character")
            refer_mode_options = {1: t("Mode 1: Use provided reference audio only"), 2: t("Mode 2: Use first audio from video as reference"), 3: t("Mode 3: Use each audio from video as reference")}
            selected_refer_mode = st.selectbox(t("Refer Mode"), options=list(refer_mode_options.keys()), format_func=lambda x: refer_mode_options[x], index=list(refer_mode_options.keys()).index(load_key("gpt_sovits.refer_mode")), help=t("Configure reference audio mode for GPT-SoVITS"))
            if selected_refer_mode != load_key("gpt_sovits.refer_mode"):
                update_key("gpt_sovits.refer_mode", selected_refer_mode)
                st.rerun()
                
        elif select_tts == "edge_tts":
            config_input(t("Edge TTS Voice"), "edge_tts.voice")

        elif select_tts == "sf_cosyvoice2":
            config_input(t("SiliconFlow API Key"), "sf_cosyvoice2.api_key")
        
        elif select_tts == "f5tts":
            config_input("302ai API", "f5tts.302_api")

def check_api():
    """
    é€šè¿‡å‘é…ç½®çš„LLMå‘é€ä¸€ä¸ªæµ‹è¯•è¯·æ±‚æ¥æ£€æŸ¥APIå¯†é’¥å’ŒURLçš„æœ‰æ•ˆæ€§ã€‚

    Returns:
        bool: å¦‚æœAPIå“åº”æˆåŠŸä¸”å†…å®¹ç¬¦åˆé¢„æœŸï¼Œåˆ™è¿”å›Trueï¼Œå¦åˆ™è¿”å›Falseã€‚
    """
    try:
        # å‘é€ä¸€ä¸ªæµ‹è¯•promptï¼ŒæœŸæœ›å¾—åˆ°ä¸€ä¸ªåŒ…å« 'message':'success' çš„JSONå“åº”
        resp = ask_gpt("This is a test, response 'message':'success' in json format.", 
                      resp_type="json", log_title='None')
        # æ£€æŸ¥å“åº”æ˜¯å¦ç¬¦åˆé¢„æœŸ
        return resp.get('message') == 'success'
    except Exception:
        # æ•è·ä»»ä½•å¼‚å¸¸ï¼ˆå¦‚ç½‘ç»œé”™è¯¯ã€è®¤è¯å¤±è´¥ç­‰ï¼‰
        return False
    
# å½“è¯¥è„šæœ¬ä½œä¸ºä¸»ç¨‹åºè¿è¡Œæ—¶ï¼Œæ‰§è¡ŒAPIæ£€æŸ¥ï¼ˆä¸»è¦ç”¨äºæµ‹è¯•ï¼‰
if __name__ == "__main__":
    check_api()
